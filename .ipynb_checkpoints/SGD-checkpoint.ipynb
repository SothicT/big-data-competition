{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv',lineterminator='\\n')\n",
    "df_test = pd.read_csv('20190425_test.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 4,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jo bhi ap se tou behtar hoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ya Allah meri sister Affia ki madad farma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yeh khud chahta a is umar main shadi krna.  ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tc ? Apky mun xe exe alfax achy nae lgty 😒💃</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             review  label\n",
       "0   1                       Jo bhi ap se tou behtar hoon      0\n",
       "1   2          ya Allah meri sister Affia ki madad farma      1\n",
       "2   3  Yeh khud chahta a is umar main shadi krna.  ha...      0\n",
       "3   4        Tc ? Apky mun xe exe alfax achy nae lgty 😒💃      0\n",
       "4   5                                               Good      1"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
=======
     "execution_count": 4,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'] = df_train['label'].map({'Negative':0,'Positive':1})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 5,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3361\n",
       "0    2967\n",
       "Name: label, dtype: int64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 6,
=======
     "execution_count": 5,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 6,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID        0\n",
       "review    0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 6,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 7,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID        0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 8,
=======
     "execution_count": 7,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 8,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'Jo bhi ap se tou behtar hoon', 0],\n",
       "       [2, 'ya Allah meri sister Affia ki madad farma', 1],\n",
       "       [3, 'Yeh khud chahta a is umar main shadi krna.  had ogi', 0],\n",
       "       [4, 'Tc ? Apky mun xe exe alfax achy nae lgty 😒💃', 0]],\n",
       "      dtype=object)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 9,
=======
     "execution_count": 8,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array = df_train.as_matrix()\n",
    "numpy_array_test = df_test.as_matrix()\n",
    "numpy_array[:4]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 9,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([116,\n",
       "       'Tahum inho ne khud ko sirf science fiction films tak he mehdood nahi rakha bal ke har mauzoo par filmy stories likhin  direction ki aur kuch films produce bhi ki'],\n",
       "      dtype=object)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 10,
=======
     "execution_count": 9,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array_test[115]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 10,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [],
   "source": [
    "#two commom ways to clean data\n",
<<<<<<< HEAD
=======
    "#数据清洗\n",
    "#re.sub(pattern, repl, string, count)：使用repl替换String中符合pattern的内容\n",
    "#pattern:正则表达式规则\n",
    "#repl：需要替换的内容\n",
    "#string：被替换的字符串\n",
    "#count：替换的次数，默认为-1，即替换所有\n",
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
    "def cleaner(word):\n",
    "  word = re.sub(r'\\#\\.', '', word)\n",
    "  word = re.sub(r'\\n', '', word)\n",
    "  word = re.sub(r',', '', word)\n",
    "  word = re.sub(r'\\-', ' ', word)\n",
    "  word = re.sub(r'\\.', '', word)\n",
    "  word = re.sub(r'\\\\', ' ', word)\n",
    "  word = re.sub(r'\\\\x\\.+', '', word)\n",
    "  word = re.sub(r'\\d', '', word)\n",
    "  word = re.sub(r'^_.', '', word)\n",
    "  word = re.sub(r'_', ' ', word)\n",
    "  word = re.sub(r'^ ', '', word)\n",
    "  word = re.sub(r' $', '', word)\n",
    "  word = re.sub(r'\\?', '', word)\n",
    "  word = re.sub(r'é', '', word)\n",
    "  word = re.sub(r'§', '', word)\n",
    "  word = re.sub(r'¦', '', word)\n",
    "  word = re.sub(r'æ', '', word)\n",
    "  word = re.sub(r'\\d+', '', word)\n",
    "  word = re.sub('(.*?)\\d+(.*?)', '', word)\n",
    "  return word.lower()\n",
    "def hashing(word):\n",
    "  word = re.sub(r'ain$', r'ein', word)\n",
    "  word = re.sub(r'ai', r'ae', word)\n",
    "  word = re.sub(r'ay$', r'e', word)\n",
    "  word = re.sub(r'ey$', r'e', word)\n",
    "  word = re.sub(r'ie$', r'y', word)\n",
    "  word = re.sub(r'^es', r'is', word)\n",
    "  word = re.sub(r'a+', r'a', word)\n",
    "  word = re.sub(r'j+', r'j', word)\n",
    "  word = re.sub(r'd+', r'd', word)\n",
    "  word = re.sub(r'u', r'o', word)\n",
    "  word = re.sub(r'o+', r'o', word)\n",
    "  word = re.sub(r'ee+', r'i', word)\n",
    "  if not re.match(r'ar', word):\n",
    "    word = re.sub(r'ar', r'r', word)\n",
    "  word = re.sub(r'iy+', r'i', word)\n",
    "  word = re.sub(r'ih+', r'eh', word)\n",
    "  word = re.sub(r's+', r's', word)\n",
    "  if re.search(r'[rst]y', 'word') and word[-1] != 'y':\n",
    "    word = re.sub(r'y', r'i', word)\n",
    "  if re.search(r'[bcdefghijklmnopqrtuvwxyz]i', word):\n",
    "    word = re.sub(r'i$', r'y', word)\n",
    "  if re.search(r'[acefghijlmnoqrstuvwxyz]h', word):\n",
    "    word = re.sub(r'h', '', word)\n",
    "  word = re.sub(r'k', r'q', word)\n",
    "  return word\n",
    "\n",
    "def array_cleaner(array):\n",
    "  # X = array\n",
    "  X = []\n",
    "  for sentence in array:\n",
    "    clean_sentence = ''\n",
<<<<<<< HEAD
=======
    "    #string.split(str=\"\", num=string.count(str))\n",
    "    #str -- 分隔符，默认为所有的空字符，包括空格、换行(\\n)、制表符(\\t)等。\n",
    "    #num -- 分割次数。默认为 -1, 即分隔所有。\n",
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
    "    words = sentence.split(' ')\n",
    "    for word in words:\n",
    "      clean_sentence = clean_sentence +' '+ cleaner(word)\n",
    "    X.append(clean_sentence)\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 14,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mulazmat ke bahali ke dua farma dein aur koe wzeefa bhee bata dein',\n",
       "       'Dua farma dain meri sehat k luay aur meray baal girna band ho jaye 1 saal say be inteha gir rahay hain',\n",
       "       'Tum khabees nahi kutti aurat ho 😂😂😂😈😈', ...,\n",
       "       'Mullah Umar Ne Afghan Hukomat amp Taliban Muzakrat Ki Himayat Kar Di Afghanistan Se Qabzay K Khatmay K Liye Muzakrat Jaiz Hen Paigham ',\n",
       "       'Embroidery ki puri ek side pe dhagay nikle hue, fabric is average.',\n",
       "       'tu marti bht h'], dtype=object)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 12,
=======
     "execution_count": 14,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
=======
    "#X-test为review内的文字\n",
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
    "X_test = numpy_array_test[:,1]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 15,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [],
   "source": [
    "#test if there are nan \n",
<<<<<<< HEAD
=======
    "#对文本进行切割，并保存在words中\n",
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
    "counter = 1\n",
    "for sentence in X_test:\n",
    "    try:\n",
    "        words = sentence.split(' ')\n",
    "        counter+=1\n",
    "    except:\n",
    "        print(sentence)\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 17,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' jo bhi ap se tou behtar hoon',\n",
       " ' ya allah meri sister affia ki madad farma',\n",
       " ' yeh khud chahta a is umar main shadi krna  had ogi',\n",
       " ' tc  apky mun xe exe alfax achy nae lgty 😒💃',\n",
       " ' good']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 14,
=======
     "execution_count": 17,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
=======
    "#对训练集以及测试集上的数据进行清洗\n",
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
    "X_train = numpy_array[:, 1]\n",
    "# Clean X here\n",
    "X_train = array_cleaner(X_train)\n",
    "X_test = array_cleaner(X_test)\n",
    "y_train = numpy_array[:, 2]\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 18,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6328\n",
      "2712\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: matplotlib_venn in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.11.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\users\\tan\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib_venn) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib_venn) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib_venn) (1.16.3)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->matplotlib_venn) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->matplotlib_venn) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->matplotlib_venn) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib->matplotlib_venn) (2.7.5)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from cycler>=0.10->matplotlib->matplotlib_venn) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->matplotlib_venn) (39.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade matplotlib_venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
=======
   "execution_count": 27,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([0, 1, 0, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 17,
=======
       "array([0, 1, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 27,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "y_train = np.array(y_train)\n",
    "y_train = y_train.astype('int8')\n",
    "y_train[:6]"
=======
    "#y_train为训练的标签\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.astype('int8')\n",
    "y_train[0:5]"
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = 2\n",
=======
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF(Term Frequency - Inverse Document Frequency的缩写，即“词频-逆文本频率”。它由两部分组成，TF和IDF。)\n",
    "#TF:表示一个词在在文本中出现的频率\n",
    "#IDF：表示一个词的重要程度（出现的越频繁其重要程度越低）\n",
    "#TfidfVecotrizer:使TF-IDF向量化表示\n",
    "ngram = 3\n",
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
    "vectorizer = TfidfVectorizer(sublinear_tf=True,ngram_range=(1, ngram), max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_train + X_test # Combine both to fit the TFIDF vectorization.\n",
    "lentrain = len(X_train)\n",
    "\n",
=======
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结合训练集以及测试集对review进行TFIDF向量化处理\n",
    "X_all = X_train + X_test # Combine both to fit the TFIDF vectorization.\n",
    "lentrain = len(X_train)\n",
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
    "vectorizer.fit(X_all) # This is the slow part!\n",
    "X_all = vectorizer.transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-aed26e02485e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
=======
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224260\n",
      "['aa', 'aa agaya', 'aa aur', 'aa aur ik', 'aa bhi']\n"
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "vectorizer.get_feature_names()[0:]"
=======
    "print(len(vectorizer.get_feature_names()))\n",
    "print(vectorizer.get_feature_names()[0:5])"
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 48,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(9040, 113355)"
      ]
     },
     "execution_count": 21,
=======
       "(9040, 224260)"
      ]
     },
     "execution_count": 48,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 49,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(6328, 113355)"
      ]
     },
     "execution_count": 22,
=======
       "(6328, 224260)"
      ]
     },
     "execution_count": 49,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_chuli = X_all[:lentrain] # Separate back into training and test sets. \n",
    "X_test_chuli = X_all[lentrain:]\n",
    "X_train_chuli.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 50,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier as SGD"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=2019)\n",
=======
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用k-折交叉法对数据集进行划分，划分为10折\n",
    "folds = StratifiedKFold(n_splits=15, shuffle=False, random_state=2019)\n",
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
    "oof = np.zeros(X_train_chuli.shape[0])\n",
    "predictions = np.zeros(X_test_chuli.shape[0])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 70,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold :1\n",
<<<<<<< HEAD
      "auc score: 0.81925 \n",
      "Fold :2\n",
      "auc score: 0.79711 \n",
      "Fold :3\n",
      "auc score: 0.79192 \n",
      "Fold :4\n",
      "auc score: 0.79341 \n",
      "Fold :5\n",
      "auc score: 0.81107 \n",
      "Fold :6\n",
      "auc score: 0.77699 \n",
      "Fold :7\n",
      "auc score: 0.82629 \n",
      "Fold :8\n",
      "auc score: 0.82403 \n",
      "Fold :9\n",
      "auc score: 0.79160 \n",
      "Fold :10\n",
      "auc score: 0.83291 \n"
=======
      "auc score: 0.88202 \n",
      "Fold :2\n",
      "auc score: 0.84136 \n",
      "Fold :3\n",
      "auc score: 0.83033 \n",
      "Fold :4\n",
      "auc score: 0.85365 \n",
      "Fold :5\n",
      "auc score: 0.84306 \n",
      "Fold :6\n",
      "auc score: 0.86251 \n",
      "Fold :7\n",
      "auc score: 0.83992 \n",
      "Fold :8\n",
      "auc score: 0.85055 \n",
      "Fold :9\n",
      "auc score: 0.81798 \n",
      "Fold :10\n",
      "auc score: 0.86406 \n",
      "Fold :11\n",
      "auc score: 0.86064 \n",
      "Fold :12\n",
      "auc score: 0.83103 \n",
      "Fold :13\n",
      "auc score: 0.84982 \n",
      "Fold :14\n",
      "auc score: 0.86519 \n",
      "Fold :15\n",
      "auc score: 0.87067 \n"
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_chuli, y_train)):\n",
    "    print(\"Fold :{}\".format(fold_ + 1))\n",
    "    trn_data = X_train_chuli[trn_idx]\n",
    "    trn_label= y_train[trn_idx]\n",
    "    val_data = X_train_chuli[val_idx]\n",
    "    val_label= y_train[val_idx]\n",
<<<<<<< HEAD
    "    model_SGD = SGD(alpha=0.00001,random_state = 2, shuffle = True, loss = 'modified_huber')                      \n",
=======
    "    model_SGD = SGD(alpha=0.00001,random_state = 2, shuffle = True, loss = 'log')                      \n",
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
    "    model_SGD.fit(trn_data, trn_label) # Fit the model.\n",
    "    print(\"auc score: {:<8.5f}\".format(metrics.roc_auc_score(val_label, model_SGD.predict_proba(val_data)[:,1])))\n",
    "    predictions += model_SGD.predict_proba(X_test_chuli)[:,1] / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 71,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([0.95366529, 0.34229378, 0.        , 1.        ])"
      ]
     },
     "execution_count": 27,
=======
       "array([5.35402604, 3.22927627, 0.32665865, 5.61440582, 2.21046638])"
      ]
     },
     "execution_count": 71,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(predictions))\n",
<<<<<<< HEAD
    "predictions[:4]"
=======
    "predictions[0:5]"
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 69,
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_output = pd.DataFrame({\"ID\":df_test[\"ID\"], \"Pred\":predictions})\n",
    "SGD_output.to_csv('SGD_new.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.0"
=======
   "version": "3.7.3"
>>>>>>> 864de870d9eb0183d755bc73f9be784cdb7e9482
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
