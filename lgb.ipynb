{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv',lineterminator='\\n')\n",
    "df_test = pd.read_csv('20190425_test.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jo bhi ap se tou behtar hoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ya Allah meri sister Affia ki madad farma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yeh khud chahta a is umar main shadi krna.  ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tc ? Apky mun xe exe alfax achy nae lgty ðŸ˜’ðŸ’ƒ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             review  label\n",
       "0   1                       Jo bhi ap se tou behtar hoon      0\n",
       "1   2          ya Allah meri sister Affia ki madad farma      1\n",
       "2   3  Yeh khud chahta a is umar main shadi krna.  ha...      0\n",
       "3   4        Tc ? Apky mun xe exe alfax achy nae lgty ðŸ˜’ðŸ’ƒ      0\n",
       "4   5                                               Good      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'] = df_train['label'].map({'Negative':0,'Positive':1})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID        0\n",
       "review    0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID        0\n",
       "review    0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3361\n",
       "0    2967\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'Jo bhi ap se tou behtar hoon', 0],\n",
       "       [2, 'ya Allah meri sister Affia ki madad farma', 1],\n",
       "       [3, 'Yeh khud chahta a is umar main shadi krna.  had ogi', 0],\n",
       "       [4, 'Tc ? Apky mun xe exe alfax achy nae lgty ðŸ˜’ðŸ’ƒ', 0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array = df_train.as_matrix()\n",
    "numpy_array_test = df_test.as_matrix()\n",
    "numpy_array[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([116,\n",
       "       'Tahum inho ne khud ko sirf science fiction films tak he mehdood nahi rakha bal ke har mauzoo par filmy stories likhin  direction ki aur kuch films produce bhi ki'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array_test[115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two commom ways to clean data\n",
    "def cleaner(word):\n",
    "  word = re.sub(r'\\#\\.', '', word)\n",
    "  word = re.sub(r'\\n', '', word)\n",
    "  word = re.sub(r',', '', word)\n",
    "  word = re.sub(r'\\-', ' ', word)\n",
    "  word = re.sub(r'\\.', '', word)\n",
    "  word = re.sub(r'\\\\', ' ', word)\n",
    "  word = re.sub(r'\\\\x\\.+', '', word)\n",
    "  word = re.sub(r'\\d', '', word)\n",
    "  word = re.sub(r'^_.', '', word)\n",
    "  word = re.sub(r'_', ' ', word)\n",
    "  word = re.sub(r'^ ', '', word)\n",
    "  word = re.sub(r' $', '', word)\n",
    "  word = re.sub(r'\\?', '', word)\n",
    "  word = re.sub(r'Ã©', '', word)\n",
    "  word = re.sub(r'Â§', '', word)\n",
    "  word = re.sub(r'Â¦', '', word)\n",
    "  word = re.sub(r'Ã¦', '', word)\n",
    "  word = re.sub(r'\\d+', '', word)\n",
    "  word = re.sub('(.*?)\\d+(.*?)', '', word)\n",
    "  return word.lower()\n",
    "def hashing(word):\n",
    "  word = re.sub(r'ain$', r'ein', word)\n",
    "  word = re.sub(r'ai', r'ae', word)\n",
    "  word = re.sub(r'ay$', r'e', word)\n",
    "  word = re.sub(r'ey$', r'e', word)\n",
    "  word = re.sub(r'ie$', r'y', word)\n",
    "  word = re.sub(r'^es', r'is', word)\n",
    "  word = re.sub(r'a+', r'a', word)\n",
    "  word = re.sub(r'j+', r'j', word)\n",
    "  word = re.sub(r'd+', r'd', word)\n",
    "  word = re.sub(r'u', r'o', word)\n",
    "  word = re.sub(r'o+', r'o', word)\n",
    "  word = re.sub(r'ee+', r'i', word)\n",
    "  if not re.match(r'ar', word):\n",
    "    word = re.sub(r'ar', r'r', word)\n",
    "  word = re.sub(r'iy+', r'i', word)\n",
    "  word = re.sub(r'ih+', r'eh', word)\n",
    "  word = re.sub(r's+', r's', word)\n",
    "  if re.search(r'[rst]y', 'word') and word[-1] != 'y':\n",
    "    word = re.sub(r'y', r'i', word)\n",
    "  if re.search(r'[bcdefghijklmnopqrtuvwxyz]i', word):\n",
    "    word = re.sub(r'i$', r'y', word)\n",
    "  if re.search(r'[acefghijlmnoqrstuvwxyz]h', word):\n",
    "    word = re.sub(r'h', '', word)\n",
    "  word = re.sub(r'k', r'q', word)\n",
    "  return word\n",
    "\n",
    "def array_cleaner(array):\n",
    "  # X = array\n",
    "  X = []\n",
    "  for sentence in array:\n",
    "    clean_sentence = ''\n",
    "    words = sentence.split(' ')\n",
    "    for word in words:\n",
    "      clean_sentence = clean_sentence +' '+ cleaner(word)\n",
    "    X.append(clean_sentence)\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mulazmat ke bahali ke dua farma dein aur koe wzeefa bhee bata dein',\n",
       "       'Dua farma dain meri sehat k luay aur meray baal girna band ho jaye 1 saal say be inteha gir rahay hain',\n",
       "       'Tum khabees nahi kutti aurat ho ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜ˆðŸ˜ˆ', ...,\n",
       "       'Mullah Umar Ne Afghan Hukomat amp Taliban Muzakrat Ki Himayat Kar Di Afghanistan Se Qabzay K Khatmay K Liye Muzakrat Jaiz Hen Paigham ',\n",
       "       'Embroidery ki puri ek side pe dhagay nikle hue, fabric is average.',\n",
       "       'tu marti bht h'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = numpy_array_test[:,1]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test if there are nan \n",
    "counter = 1\n",
    "for sentence in X_test:\n",
    "    try:\n",
    "        words = sentence.split(' ')\n",
    "        counter+=1\n",
    "    except:\n",
    "        print(sentence)\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' jo bhi ap se tou behtar hoon',\n",
       " ' ya allah meri sister affia ki madad farma',\n",
       " ' yeh khud chahta a is umar main shadi krna  had ogi',\n",
       " ' tc  apky mun xe exe alfax achy nae lgty ðŸ˜’ðŸ’ƒ',\n",
       " ' good']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = numpy_array[:, 1]\n",
    "# Clean X here\n",
    "X_train = array_cleaner(X_train)\n",
    "X_test = array_cleaner(X_test)\n",
    "y_train = numpy_array[:, 2]\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6328\n",
      "2712\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6328,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train = y_train.astype('int8')\n",
    "print(y_train.shape)\n",
    "y_train[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.Series(y_train)\n",
    "test1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = 2\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True,ngram_range=(1, ngram), max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_train + X_test # Combine both to fit the TFIDF vectorization.\n",
    "lentrain = len(X_train)\n",
    "\n",
    "vectorizer.fit(X_all)\n",
    "X_all = vectorizer.transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['è³­easar ul', 'é„­h', 'é„­h isnan', 'é„­pwa', 'é„­pwa yani']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9040, 113355)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chuli = X_all[:lentrain] # Separate back into training and test sets. \n",
    "X_test_chuli = X_all[lentrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6328, 113355)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_chuli.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\tan\\appdata\\roaming\\python\\python37\\site-packages (from lightgbm) (1.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from lightgbm) (1.14.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tan\\appdata\\roaming\\python\\python37\\site-packages (from lightgbm) (0.20.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayesian optimization to find hyperparameter for lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_CV(\n",
    "          min_data_in_leaf,\n",
    "          feature_fraction,\n",
    "          bagging_fraction,\n",
    "         ):\n",
    "    \n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "    oof = np.zeros(X_train_chuli.shape[0])\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_chuli, y_train)):\n",
    "        print(\"fold nÂ°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(X_train_chuli[trn_idx],\n",
    "                               label=y_train[trn_idx],\n",
    "                               )\n",
    "        val_data = lgb.Dataset(X_train_chuli[val_idx],\n",
    "                               label=y_train[val_idx],\n",
    "                               )\n",
    "    \n",
    "        param = {\n",
    "            'max_depth': -1,\n",
    "            'min_data_in_leaf': int(min_data_in_leaf), \n",
    "            'objective':'binary',\n",
    "            'bagging_fraction':bagging_fraction,\n",
    "            'feature_fraction':feature_fraction,\n",
    "            'learning_rate': 0.005,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"bagging_freq\": 5,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"metric\": 'auc',\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "    \n",
    "        clf = lgb.train(param,\n",
    "                        trn_data,\n",
    "                        8000,\n",
    "                        valid_sets = [trn_data, val_data],\n",
    "                        verbose_eval=500,\n",
    "                        early_stopping_rounds = 500)\n",
    "        \n",
    "        oof[val_idx] = clf.predict(X_train_chuli[val_idx],\n",
    "                                   num_iteration=clf.best_iteration)\n",
    "        \n",
    "        del clf, trn_idx, val_idx\n",
    "        \n",
    "    return metrics.roc_auc_score(y_train,oof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_BO = BayesianOptimization(LGB_CV, {\n",
    "        'min_data_in_leaf': (2, 40),\n",
    "        'bagging_fraction': (0.01, 0.999),\n",
    "        'feature_fraction':(0.01, 0.999)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | min_da... |\n",
      "-------------------------------------------------------------\n",
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.842926\tvalid_1's auc: 0.770715\n",
      "[1000]\ttraining's auc: 0.874774\tvalid_1's auc: 0.774532\n",
      "[1500]\ttraining's auc: 0.896607\tvalid_1's auc: 0.772278\n",
      "Early stopping, best iteration is:\n",
      "[1170]\ttraining's auc: 0.882696\tvalid_1's auc: 0.77486\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.844161\tvalid_1's auc: 0.758139\n",
      "[1000]\ttraining's auc: 0.875512\tvalid_1's auc: 0.763042\n",
      "[1500]\ttraining's auc: 0.897401\tvalid_1's auc: 0.762979\n",
      "Early stopping, best iteration is:\n",
      "[1341]\ttraining's auc: 0.891025\tvalid_1's auc: 0.764019\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.844765\tvalid_1's auc: 0.738737\n",
      "[1000]\ttraining's auc: 0.877674\tvalid_1's auc: 0.754196\n",
      "[1500]\ttraining's auc: 0.898784\tvalid_1's auc: 0.75759\n",
      "[2000]\ttraining's auc: 0.915783\tvalid_1's auc: 0.758388\n",
      "Early stopping, best iteration is:\n",
      "[1872]\ttraining's auc: 0.911792\tvalid_1's auc: 0.759245\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.83816\tvalid_1's auc: 0.779092\n",
      "[1000]\ttraining's auc: 0.870948\tvalid_1's auc: 0.788567\n",
      "[1500]\ttraining's auc: 0.893587\tvalid_1's auc: 0.788367\n",
      "Early stopping, best iteration is:\n",
      "[1315]\ttraining's auc: 0.885498\tvalid_1's auc: 0.789356\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.841654\tvalid_1's auc: 0.770577\n",
      "[1000]\ttraining's auc: 0.875259\tvalid_1's auc: 0.779564\n",
      "[1500]\ttraining's auc: 0.897532\tvalid_1's auc: 0.778583\n",
      "Early stopping, best iteration is:\n",
      "[1116]\ttraining's auc: 0.88072\tvalid_1's auc: 0.780224\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7724  \u001b[0m | \u001b[0m 0.7874  \u001b[0m | \u001b[0m 0.5739  \u001b[0m | \u001b[0m 24.66   \u001b[0m |\n",
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.769581\tvalid_1's auc: 0.719008\n",
      "[1000]\ttraining's auc: 0.782403\tvalid_1's auc: 0.722843\n",
      "[1500]\ttraining's auc: 0.793415\tvalid_1's auc: 0.723619\n",
      "Early stopping, best iteration is:\n",
      "[1471]\ttraining's auc: 0.792715\tvalid_1's auc: 0.72473\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.772047\tvalid_1's auc: 0.707961\n",
      "[1000]\ttraining's auc: 0.787791\tvalid_1's auc: 0.71329\n",
      "[1500]\ttraining's auc: 0.798392\tvalid_1's auc: 0.715745\n",
      "[2000]\ttraining's auc: 0.808166\tvalid_1's auc: 0.716045\n",
      "[2500]\ttraining's auc: 0.816179\tvalid_1's auc: 0.715859\n",
      "Early stopping, best iteration is:\n",
      "[2367]\ttraining's auc: 0.814098\tvalid_1's auc: 0.716739\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.776332\tvalid_1's auc: 0.699273\n",
      "[1000]\ttraining's auc: 0.791442\tvalid_1's auc: 0.705765\n",
      "[1500]\ttraining's auc: 0.801125\tvalid_1's auc: 0.706867\n",
      "[2000]\ttraining's auc: 0.810207\tvalid_1's auc: 0.70798\n",
      "[2500]\ttraining's auc: 0.817409\tvalid_1's auc: 0.709378\n",
      "[3000]\ttraining's auc: 0.824099\tvalid_1's auc: 0.70993\n",
      "Early stopping, best iteration is:\n",
      "[2580]\ttraining's auc: 0.81843\tvalid_1's auc: 0.710242\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.769843\tvalid_1's auc: 0.708559\n",
      "[1000]\ttraining's auc: 0.784696\tvalid_1's auc: 0.714001\n",
      "[1500]\ttraining's auc: 0.792794\tvalid_1's auc: 0.716664\n",
      "[2000]\ttraining's auc: 0.801737\tvalid_1's auc: 0.719312\n",
      "[2500]\ttraining's auc: 0.809087\tvalid_1's auc: 0.719468\n",
      "[3000]\ttraining's auc: 0.815971\tvalid_1's auc: 0.718896\n",
      "Early stopping, best iteration is:\n",
      "[2727]\ttraining's auc: 0.812359\tvalid_1's auc: 0.719901\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.769961\tvalid_1's auc: 0.723671\n",
      "[1000]\ttraining's auc: 0.783496\tvalid_1's auc: 0.728663\n",
      "[1500]\ttraining's auc: 0.793862\tvalid_1's auc: 0.732597\n",
      "[2000]\ttraining's auc: 0.802809\tvalid_1's auc: 0.732922\n",
      "Early stopping, best iteration is:\n",
      "[1617]\ttraining's auc: 0.796326\tvalid_1's auc: 0.733258\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7189  \u001b[0m | \u001b[0m 0.534   \u001b[0m | \u001b[0m 0.1145  \u001b[0m | \u001b[0m 39.52   \u001b[0m |\n",
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.640762\tvalid_1's auc: 0.619142\n",
      "[1000]\ttraining's auc: 0.676656\tvalid_1's auc: 0.645802\n",
      "[1500]\ttraining's auc: 0.683638\tvalid_1's auc: 0.653958\n",
      "Early stopping, best iteration is:\n",
      "[1300]\ttraining's auc: 0.687214\tvalid_1's auc: 0.654875\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.617347\tvalid_1's auc: 0.58269\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.596869\tvalid_1's auc: 0.605165\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.645958\tvalid_1's auc: 0.5921\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's auc: 0.646313\tvalid_1's auc: 0.621824\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.636716\tvalid_1's auc: 0.611103\n",
      "[1000]\ttraining's auc: 0.649499\tvalid_1's auc: 0.614777\n",
      "[1500]\ttraining's auc: 0.67165\tvalid_1's auc: 0.640656\n",
      "[2000]\ttraining's auc: 0.685871\tvalid_1's auc: 0.65281\n",
      "[2500]\ttraining's auc: 0.69202\tvalid_1's auc: 0.653688\n",
      "Early stopping, best iteration is:\n",
      "[2189]\ttraining's auc: 0.690077\tvalid_1's auc: 0.662377\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.622433\tvalid_1's auc: 0.614127\n",
      "[1000]\ttraining's auc: 0.64876\tvalid_1's auc: 0.643415\n",
      "[1500]\ttraining's auc: 0.66614\tvalid_1's auc: 0.658321\n",
      "[2000]\ttraining's auc: 0.680748\tvalid_1's auc: 0.678286\n",
      "[2500]\ttraining's auc: 0.689186\tvalid_1's auc: 0.683522\n",
      "[3000]\ttraining's auc: 0.696057\tvalid_1's auc: 0.69272\n",
      "[3500]\ttraining's auc: 0.695734\tvalid_1's auc: 0.689843\n",
      "Early stopping, best iteration is:\n",
      "[3232]\ttraining's auc: 0.699485\tvalid_1's auc: 0.698086\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6274  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.485   \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 28.2    \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "LGB_BO.maximize(init_points=2,n_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.879002\tvalid_1's auc: 0.790315\n",
      "[1000]\ttraining's auc: 0.932447\tvalid_1's auc: 0.802947\n",
      "[1500]\ttraining's auc: 0.961179\tvalid_1's auc: 0.807213\n",
      "[2000]\ttraining's auc: 0.978141\tvalid_1's auc: 0.809524\n",
      "[2500]\ttraining's auc: 0.987611\tvalid_1's auc: 0.810058\n",
      "[3000]\ttraining's auc: 0.993031\tvalid_1's auc: 0.810405\n",
      "[3500]\ttraining's auc: 0.99613\tvalid_1's auc: 0.810717\n",
      "Early stopping, best iteration is:\n",
      "[3269]\ttraining's auc: 0.994952\tvalid_1's auc: 0.811215\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.880803\tvalid_1's auc: 0.782901\n",
      "[1000]\ttraining's auc: 0.932914\tvalid_1's auc: 0.797981\n",
      "[1500]\ttraining's auc: 0.961158\tvalid_1's auc: 0.802665\n",
      "[2000]\ttraining's auc: 0.977653\tvalid_1's auc: 0.805107\n",
      "[2500]\ttraining's auc: 0.987441\tvalid_1's auc: 0.807167\n",
      "[3000]\ttraining's auc: 0.993237\tvalid_1's auc: 0.807052\n",
      "Early stopping, best iteration is:\n",
      "[2555]\ttraining's auc: 0.98829\tvalid_1's auc: 0.807331\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.881833\tvalid_1's auc: 0.769352\n",
      "[1000]\ttraining's auc: 0.933568\tvalid_1's auc: 0.789164\n",
      "[1500]\ttraining's auc: 0.962475\tvalid_1's auc: 0.796222\n",
      "[2000]\ttraining's auc: 0.979013\tvalid_1's auc: 0.799401\n",
      "[2500]\ttraining's auc: 0.988204\tvalid_1's auc: 0.801473\n",
      "[3000]\ttraining's auc: 0.993599\tvalid_1's auc: 0.803383\n",
      "[3500]\ttraining's auc: 0.996469\tvalid_1's auc: 0.805073\n",
      "[4000]\ttraining's auc: 0.99801\tvalid_1's auc: 0.805764\n",
      "[4500]\ttraining's auc: 0.998751\tvalid_1's auc: 0.806912\n",
      "[5000]\ttraining's auc: 0.999162\tvalid_1's auc: 0.807268\n",
      "[5500]\ttraining's auc: 0.999424\tvalid_1's auc: 0.806963\n",
      "Early stopping, best iteration is:\n",
      "[5193]\ttraining's auc: 0.999275\tvalid_1's auc: 0.807415\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.877065\tvalid_1's auc: 0.807522\n",
      "[1000]\ttraining's auc: 0.930971\tvalid_1's auc: 0.828982\n",
      "[1500]\ttraining's auc: 0.961329\tvalid_1's auc: 0.837253\n",
      "[2000]\ttraining's auc: 0.97846\tvalid_1's auc: 0.840818\n",
      "[2500]\ttraining's auc: 0.988246\tvalid_1's auc: 0.843555\n",
      "[3000]\ttraining's auc: 0.993729\tvalid_1's auc: 0.844991\n",
      "[3500]\ttraining's auc: 0.996662\tvalid_1's auc: 0.846354\n",
      "[4000]\ttraining's auc: 0.998118\tvalid_1's auc: 0.847815\n",
      "[4500]\ttraining's auc: 0.998779\tvalid_1's auc: 0.848013\n",
      "[5000]\ttraining's auc: 0.999093\tvalid_1's auc: 0.84884\n",
      "[5500]\ttraining's auc: 0.999323\tvalid_1's auc: 0.848737\n",
      "Early stopping, best iteration is:\n",
      "[5388]\ttraining's auc: 0.999278\tvalid_1's auc: 0.849023\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.880343\tvalid_1's auc: 0.789956\n",
      "[1000]\ttraining's auc: 0.933282\tvalid_1's auc: 0.807964\n",
      "[1500]\ttraining's auc: 0.96273\tvalid_1's auc: 0.814661\n",
      "[2000]\ttraining's auc: 0.979213\tvalid_1's auc: 0.817642\n",
      "[2500]\ttraining's auc: 0.988658\tvalid_1's auc: 0.819089\n",
      "[3000]\ttraining's auc: 0.993826\tvalid_1's auc: 0.820579\n",
      "[3500]\ttraining's auc: 0.996596\tvalid_1's auc: 0.820607\n",
      "[4000]\ttraining's auc: 0.998013\tvalid_1's auc: 0.820577\n",
      "Early stopping, best iteration is:\n",
      "[3670]\ttraining's auc: 0.997202\tvalid_1's auc: 0.821023\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof = np.zeros(X_train_chuli.shape[0])\n",
    "predictions = np.zeros(X_test_chuli.shape[0])\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_chuli, y_train)):\n",
    "    print(\"fold nÂ°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X_train_chuli[trn_idx],\n",
    "                           label=y_train[trn_idx],\n",
    "                           )\n",
    "    val_data = lgb.Dataset(X_train_chuli[val_idx],\n",
    "                           label=y_train[val_idx],\n",
    "                           )\n",
    "\n",
    "    param = {\n",
    "        'max_depth': -1,\n",
    "        'min_data_in_leaf': 2, \n",
    "        'objective':'binary',\n",
    "        'bagging_fraction':0.999,\n",
    "        'feature_fraction':0.999,\n",
    "        'learning_rate': 0.005,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"bagging_freq\": 5,\n",
    "        \"bagging_seed\": 11,\n",
    "        \"metric\": 'auc',\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    8000,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 500)\n",
    "\n",
    "    oof[val_idx] = clf.predict(X_train_chuli[val_idx],\n",
    "                               num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(X_test_chuli, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87350113, 0.6612115 , 0.03153293, 0.91210489])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "predictions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_output = pd.DataFrame({\"ID\":df_test[\"ID\"], \"Pred\":predictions})\n",
    "lgb_output.to_csv('lgb_new.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
